Node.js Express backend that connects the AI chat frontend to **Groq's LLaMA3 API**. Handles prompt requests, CORS validation, rate limiting, and input validations.

---

## ğŸ§  AI Model Used

-   **Provider**: Groq
-   **Model**: LLaMA3-70B-8192
-   **API**: [https://api.groq.com/openai/v1/chat/completions](https://api.groq.com/openai/v1/chat/completions)

---

## ğŸ“¦ Tech Stack

-   Node.js
-   Express.js
-   dotenv
-   axios
-   helmet
-   cors
-   express-rate-limit

---

## ğŸ› ï¸ Local Setup

```bash
git clone https://github.com/a2rp/gemini-chat-backend.git
cd gemini-chat-backend
npm install
```
